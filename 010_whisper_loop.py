# filename: talkback_faster_whisper_vad.py
import os
from faster_whisper import WhisperModel

from voice_recorder import record_until_silence, write_wav

# =========================
# Config
# =========================
TEMP_WAV = "/tmp/asr_input.wav"
WHISPER_MODEL_SIZE = os.getenv("WHISPER_SIZE", "small")   # å¯æ”¹ "tiny" / "base" / "small" / "medium" / "large-v3"
WHISPER_DEVICE = os.getenv("WHISPER_DEVICE", "auto")      # "cpu" / "cuda" / "auto"
WHISPER_PREC = os.getenv("WHISPER_PREC", "int8")          # "int8" / "int8_float16" / "float16" / "float32"
LANG = os.getenv("ASR_LANG", "zh")                        # é è¨­ä¸­æ–‡
INPUT_DEVICE_INDEX = None                                  # å¦‚éœ€æŒ‡å®šéº¥å…‹é¢¨ï¼Œå¯å¡«æ•´æ•¸ index

# faster-whisper åƒæ•¸ï¼ˆå¯ä¾ä½ çš„ Pi 5 / Hailo æ­é…åšèª¿æ•´ï¼Œé€™è£¡ä¸ä½¿ç”¨ Hailoï¼Œå–®ç´” CPU/GPUï¼‰
TRANSCRIBE_KW = dict(
    language=LANG,
    beam_size=5,
    vad_filter=False,              # æˆ‘å€‘å·²ç”¨ç°¡æ˜“ VAD æˆªæ–·å¥å­ï¼Œæ•…é—œé–‰å…§å»º VAD
    condition_on_previous_text=False,
    temperature=0.0,
)

def main():
    print(f"[asr] Loading faster-whisper model '{WHISPER_MODEL_SIZE}' (device={WHISPER_DEVICE}, compute_type={WHISPER_PREC}) ...")
    model = WhisperModel(WHISPER_MODEL_SIZE, device=WHISPER_DEVICE, compute_type=WHISPER_PREC)

    print("Talkback (faster-whisper) is running.")
    print("æˆ‘æœƒç„¡é™è¿´åœˆï¼šéŒ„éŸ³â†’è¾¨è­˜â†’å°å‡ºçµæœã€‚æŒ‰ Ctrl+C é›¢é–‹ã€‚")

    try:
        while True:
            # 1) éŒ„åˆ°ä¸€æ®µèªéŸ³ï¼ˆç›´åˆ°åµæ¸¬åˆ°éœéŸ³çµæŸï¼‰
            audio_bytes, noise_floor, threshold = record_until_silence()

            if not audio_bytes:
                print("[asr] No audio captured. Listening again...")
                continue

            # 2) å­˜æˆ wavï¼ˆ16k/å–®è²é“/16bitï¼‰
            write_wav(TEMP_WAV, audio_bytes)
            print(f"[asr] Saved input to {TEMP_WAV} (noiseâ‰ˆ{noise_floor:.1f}, thrâ‰ˆ{threshold:.1f})")

            # 3) è½‰æ–‡å­—
            print("[asr] Transcribing...")
            try:
                segments, info = model.transcribe(TEMP_WAV, **TRANSCRIBE_KW)

                # è¼¸å‡ºé€æ®µèˆ‡åˆä½µçµæœ
                final_text_parts = []
                for s in segments:
                    print(f"[{s.start:.2f}-{s.end:.2f}] {s.text}")
                    final_text_parts.append(s.text)

                final_text = "".join(final_text_parts).strip()
                if final_text:
                    print(f"[asr] >> {final_text}")
                else:
                    print("[asr] No speech detected.")
            except KeyboardInterrupt:
                raise
            except Exception as e:
                print(f"[asr] Exception: {e}")

            # 4) å›åˆ°è†è½
            print("[asr] Listening again... (Ctrl+C to Quit)")

    except KeyboardInterrupt:
        print("\nBye! ğŸ‘‹")

if __name__ == "__main__":
    main()
